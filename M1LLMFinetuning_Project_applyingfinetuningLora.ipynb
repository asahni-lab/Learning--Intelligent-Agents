{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af9b2d0",
   "metadata": {},
   "source": [
    "# Walkthrough: Applying LoRA (Optional)\n",
    "\n",
    "## Introduction\n",
    "In this reading, we’ll go step-by-step through the proper solution for the activity where you applied Low-Rank Adaptation (LoRA) to fine-tune a pretrained model. By following these steps, you will understand how to fine-tune a large language model (LLM) efficiently using fewer computational resources while achieving solid performance on task-specific data.\n",
    "\n",
    "By the end of this reading, you will be able to:\n",
    "- Apply LoRA to fine-tune a large pretrained model efficiently.\n",
    "- Fine-tune specific model layers while freezing the majority of parameters.\n",
    "- Evaluate and optimize the performance of a LoRA-enhanced model.\n",
    "\n",
    "## Step-by-step guide to fine-tuning with LoRA\n",
    "This reading will guide you through the following steps:\n",
    "- Step 1: Prepare your dataset\n",
    "- Step 2: Apply LoRA to the model\n",
    "- Step 3: Fine-tune the LoRA-enhanced model\n",
    "- Step 4: Evaluate the fine-tuned model\n",
    "- Step 5: Optimize LoRA for better performance\n",
    "\n",
    "### Step 1: Prepare your dataset\n",
    "As always, the first step is preparing the dataset for fine-tuning. This involves splitting the dataset into training, validation, and test sets, as well as performing necessary preprocessing such as cleaning and tokenization.\n",
    "\n",
    "**Instructions**\n",
    "- Load the dataset and inspect its structure.\n",
    "- Split the dataset into training, validation, and test sets to ensure the model generalizes well.\n",
    "- Apply preprocessing steps, such as cleaning the text and tokenizing the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ca8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Split dataset into training (70%), validation (15%), and test (15%)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4243152",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "We split the dataset into three parts: training, validation, and test. This ensures that the model is fine-tuned on one subset of the data while being evaluated on unseen data to gauge its generalization capabilities.\n",
    "\n",
    "### Step 2: Apply LoRA to the model\n",
    "LoRA allows you to fine-tune a pretrained model efficiently by introducing low-rank matrices to a subset of the model’s parameters. In this step, we will apply LoRA to specific layers of the model (e.g., attention layers) and freeze the rest of the parameters.\n",
    "\n",
    "**Instructions**\n",
    "- Load the pretrained model (e.g., BERT).\n",
    "- Apply LoRA to the relevant layers, such as attention heads or feed-forward layers.\n",
    "- Freeze the remaining parameters to ensure only the LoRA-modified matrices are updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lora import LoRALayer\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load a pretrained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Apply LoRA to specific layers (e.g., attention layers)\n",
    "for name, module in model.named_modules():\n",
    "    if 'attention' in name:\n",
    "        module.apply(LoRALayer)\n",
    "\n",
    "# Freeze the rest of the model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649776f",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "We use the LoRALayer function to apply LoRA to specific parts of the model (such as attention layers) while freezing the rest of the parameters to ensure that only the low-rank matrices are fine-tuned.\n",
    "\n",
    "### Step 3: Fine-tune the LoRA-enhanced model\n",
    "Now that LoRA has been applied, we proceed with fine-tuning the model on our task-specific dataset. This process updates only the LoRA-modified layers, resulting in a much more efficient fine-tuning process compared to traditional methods.\n",
    "\n",
    "**Instructions**\n",
    "- Set up the training arguments, including learning rate, batch size, and number of epochs.\n",
    "- Fine-tune the model using the training data and validate the performance after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Initialize Trainer for fine-tuning\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    ")\n",
    "\n",
    "# Start fine-tuning the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ffa640",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "We use Trainer from the Hugging Face library to fine-tune the model. Only the low-rank matrices introduced by LoRA are updated during training, while the rest of the model remains frozen.\n",
    "\n",
    "### Step 4: Evaluate the fine-tuned model\n",
    "After fine-tuning, it’s time to evaluate the model on the test set to measure its performance on unseen data. This step helps determine how well the model generalizes beyond the training and validation sets.\n",
    "\n",
    "**Instructions**\n",
    "- Evaluate the model’s performance on the test set using accuracy, precision, recall, or F1 score.\n",
    "- Compare the results to a traditionally fine-tuned model to observe the efficiency gains with LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "results = trainer.evaluate(eval_dataset=test_data)\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = trainer.predict(test_data).predictions.argmax(-1)\n",
    "true_labels = test_data['label']\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = results['eval_accuracy']\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "# Print all evaluation metrics\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ebcde",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "The evaluation results will provide insights into how well the LoRA-enhanced model performs on new, unseen examples. Learners can compare multiple metrics to gain a well-rounded understanding of the model’s performance.\n",
    "\n",
    "### Step 5: Optimize LoRA for better performance\n",
    "You can further optimize LoRA by adjusting the rank of the low-rank matrices or fine-tuning additional layers of the model. This step allows you to experiment and find the best configuration for your specific task.\n",
    "\n",
    "**Optional instructions**\n",
    "- Try fine-tuning different layers with LoRA.\n",
    "- Adjust the rank of the low-rank matrices to balance model efficiency and performance.\n",
    "- Experiment with other parameters, such as alpha (scaling factor for LoRA), dropout, and bias, to see how they affect the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lora import adjust_lora_rank\n",
    "\n",
    "# Adjust the rank for LoRA\n",
    "adjust_lora_rank(model, rank=4)  # Experiment with different rank values\n",
    "\n",
    "# Experiment with additional parameters\n",
    "alpha = 16 # Scaling factor for LoRA\n",
    "dropout_rate = 0.1 # Dropout rate for regularization\n",
    "use_bias = True # Whether to include bias in the model layers\n",
    "\n",
    "# Example of modifying these parameters\n",
    "if hasattr(model.config, 'alpha'):\n",
    "    model.config.alpha = alpha\n",
    "else:\n",
    "    print(\"Warning: model.config does not have attribute 'alpha'\")\n",
    "\n",
    "if hasattr(model.config, 'hidden_dropout_prob'):\n",
    "    model.config.hidden_dropout_prob = dropout_rate\n",
    "else:\n",
    "    print(\"Warning: model.config does not have attribute 'hidden_dropout_prob'\")\n",
    "\n",
    "if hasattr(model.config, 'use_bias'):\n",
    "    model.config.use_bias = use_bias\n",
    "else:\n",
    "    print(\"Warning: model.config does not have attribute 'use_bias'\")\n",
    "\n",
    "print(f\"Alpha: {alpha}\")\n",
    "print(f\"Dropout Rate: {dropout_rate}\")\n",
    "print(f\"Using Bias: {use_bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6436f51",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "By experimenting with the rank of the low-rank matrices and additional parameters such as alpha, dropout, and bias, learners can explore how these changes impact the model’s performance and efficiency.\n",
    "\n",
    "## Conclusion\n",
    "In this walkthrough, we’ve explored the step-by-step solution to fine-tuning a pretrained model using LoRA. We reduced the computational cost by applying low-rank adaptation to specific model layers while still achieving high performance on task-specific data. LoRA is a powerful technique for efficiently fine-tuning large models and is ideal for scenarios where resources are limited."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
