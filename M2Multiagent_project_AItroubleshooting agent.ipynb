{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9891e4e",
   "metadata": {},
   "source": [
    "## 0) Setup & Configuration\n",
    "We will use `transformers` for modern NLP, `nltk` for educational comparisons, and `scikit-learn` for classic ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk transformers scikit-learn torch --quiet\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    ")\n",
    "\n",
    "# Classic ML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ----- Notebook configuration toggles -----\n",
    "METHOD_INTENT = \"zero_shot\"     # options: \"zero_shot\" | \"logreg\"\n",
    "METHOD_POLICY = \"bandit\"        # options: \"rules\" | \"bandit\" | \"llm_planner\"\n",
    "\n",
    "# Paths for simulated logging (learning from data)\n",
    "LOG_DIR = Path(\"logs\")\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "LOG_FILE = LOG_DIR / \"conversations.jsonl\"\n",
    "\n",
    "print(\"Setup complete. Configuration:\")\n",
    "print(f\"Intent Method: {METHOD_INTENT}\")\n",
    "print(f\"Policy Method: {METHOD_POLICY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63cc375",
   "metadata": {},
   "source": [
    "## 1) Tokenization — What & Why\n",
    "**What:** Split text into tokens (words/subwords).\n",
    "**Why:** Models operate on tokens; modern transformers use subword tokenization for robust handling of rare words.\n",
    "\n",
    "*   **NLTK** is fine for learning (word-level tokens).\n",
    "*   **Transformers** ship with their own tokenizer (WordPiece/BPE/SentencePiece). **Always use the model’s tokenizer when feeding transformer models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample query\n",
    "query = \"My laptop is overheating after the latest update.\"\n",
    "\n",
    "# NLTK word tokenization (educational)\n",
    "tokens_nltk = word_tokenize(query)\n",
    "print(\"NLTK tokens:\", tokens_nltk)\n",
    "\n",
    "# Model tokenizer (example: BERT base uncased)\n",
    "# Note: This downloads the tokenizer vocabulary\n",
    "tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokens_model = tok.tokenize(query)\n",
    "print(\"Model tokens:\", tokens_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85962a0",
   "metadata": {},
   "source": [
    "## 2) Named Entity Recognition (NER) — What & Why\n",
    "**What:** Extract entities like org names, dates, products.\n",
    "**Why:** Helps tailor solutions and route KB lookups (e.g., “update”, “laptop”, “Microsoft”, “1975”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a pre-trained NER pipeline\n",
    "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "entities = ner(query)\n",
    "print(\"NER:\", entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce7057",
   "metadata": {},
   "source": [
    "## 3) POS Tagging — What & Why\n",
    "**What:** Assign parts of speech (noun, verb, adjective).\n",
    "**Why:** Useful for shallow parsing, understanding structure (e.g., the subject “laptop”, the predicate “is overheating”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face POS model (token classification)\n",
    "pos_model_name = \"vblagoje/bert-english-uncased-finetuned-pos\"\n",
    "pos_tokenizer = AutoTokenizer.from_pretrained(pos_model_name)\n",
    "pos_model = AutoModelForTokenClassification.from_pretrained(pos_model_name)\n",
    "\n",
    "pos_pipeline = pipeline(\"token-classification\", model=pos_model, tokenizer=pos_tokenizer, aggregation_strategy=\"simple\")\n",
    "pos_tags = pos_pipeline(query)\n",
    "print(\"POS tags:\", pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b8024",
   "metadata": {},
   "source": [
    "## 4) Sentiment Analysis — What & Why\n",
    "**What:** Classify the tone (positive/negative).\n",
    "**Why:** Use empathetic language, decide when to escalate sooner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "sent = sentiment(query)[0]\n",
    "print(\"Sentiment:\", sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6290ae",
   "metadata": {},
   "source": [
    "## 5) Intent Detection — Two Options\n",
    "\n",
    "### A) Zero-shot Intent (Transformers)\n",
    "**Why:** No labeled data needed; works well to start.\n",
    "**How:** Compare user text against candidate intents and pick the highest score.\n",
    "\n",
    "### B) Classic ML (TF‑IDF + Logistic Regression)\n",
    "**Why:** Teaches supervised learning foundations; requires small labeled examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e03130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Option A: Zero-shot ---\n",
    "candidate_intents = [\"overheating\", \"slow_performance\", \"battery_issue\", \"network_issue\", \"update_issue\"]\n",
    "zero_shot = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "z = zero_shot(query, candidate_intents, multi_label=False)\n",
    "intent_label = z[\"labels\"][0] if z[\"scores\"][0] >= 0.5 else None\n",
    "\n",
    "# --- Option B: Classic ML (TF-IDF + LogReg) ---\n",
    "# Synthetic labeled training data (for demo)\n",
    "train_texts = [\n",
    "    \"My laptop is overheating after an update\",\n",
    "    \"The system is very slow today\",\n",
    "    \"Battery drains quickly while idle\",\n",
    "    \"Wi-Fi disconnects frequently\",\n",
    "    \"Update caused errors and rollback failed\",\n",
    "]\n",
    "train_labels = [\"overheating\", \"slow_performance\", \"battery_issue\", \"network_issue\", \"update_issue\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "X = vectorizer.fit_transform(train_texts)\n",
    "clf = LogisticRegression(max_iter=500)\n",
    "clf.fit(X, train_labels)\n",
    "\n",
    "Xq = vectorizer.transform([query])\n",
    "intent_ml = clf.predict(Xq)[0]\n",
    "intent_proba = clf.predict_proba(Xq).max()\n",
    "\n",
    "print(\"LogReg intent:\", intent_ml, \"confidence:\", round(intent_proba, 3))\n",
    "\n",
    "# --- Selection ---\n",
    "if METHOD_INTENT == \"zero_shot\":\n",
    "    intent = intent_label\n",
    "elif METHOD_INTENT == \"logreg\":\n",
    "    intent = intent_ml\n",
    "else:\n",
    "    intent = None\n",
    "\n",
    "print(f\"Selected intent ({METHOD_INTENT}):\", intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc737b6f",
   "metadata": {},
   "source": [
    "## 6) Slot Filling (Context Capture)\n",
    "Define minimal slots required per intent. These drive the decision policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38112318",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_SLOTS = {\n",
    "    \"overheating\": [\"is_after_update\", \"fan_noise\", \"when_started\", \"ambient_temp\"],\n",
    "    \"slow_performance\": [\"cpu_usage\", \"recent_changes\", \"when_started\"],\n",
    "    \"battery_issue\": [\"when_started\", \"charge_cycles\", \"power_settings\"],\n",
    "    \"network_issue\": [\"is_wifi\", \"other_devices_ok\", \"when_started\"],\n",
    "    \"update_issue\": [\"which_update\", \"rollback_possible\", \"error_codes\"],\n",
    "}\n",
    "\n",
    "SLOT_QUESTIONS = {\n",
    "    \"is_after_update\": \"Did this start after a recent OS or driver update? (yes/no)\",\n",
    "    \"fan_noise\": \"Is the fan noticeably louder than usual? (yes/no)\",\n",
    "    \"when_started\": \"When did the issue start? (e.g., yesterday, after an update)\",\n",
    "    \"ambient_temp\": \"Is the room temperature unusually hot? (yes/no)\",\n",
    "    \"cpu_usage\": \"Have you noticed high CPU usage in Task Manager? (yes/no)\",\n",
    "    \"recent_changes\": \"Any recent software installs or configuration changes? (list or 'no')\",\n",
    "    \"charge_cycles\": \"Approximately how many battery charge cycles?\",\n",
    "    \"power_settings\": \"Are you using performance or power-saver plan?\",\n",
    "    \"is_wifi\": \"Is the issue on Wi‑Fi, Ethernet, or both?\",\n",
    "    \"other_devices_ok\": \"Do other devices on the same network work fine? (yes/no)\",\n",
    "    \"which_update\": \"Which update was installed? (version/build/date if known)\",\n",
    "    \"rollback_possible\": \"Can you try rolling back the update? (yes/no)\",\n",
    "    \"error_codes\": \"Any error codes or Event Viewer logs you can share?\",\n",
    "}\n",
    "\n",
    "# Simple heuristic pre-fill using NER and regex\n",
    "slots = {}\n",
    "if intent == \"overheating\" and re.search(r\"\\bupdate\\b\", query, flags=re.I):\n",
    "    slots[\"is_after_update\"] = \"yes\"\n",
    "\n",
    "if any(e.get(\"entity_group\") == \"DATE\" for e in entities):\n",
    "    slots[\"when_started\"] = next((e[\"word\"] for e in entities if e[\"entity_group\"] == \"DATE\"), None)\n",
    "\n",
    "print(\"Initial slots:\", slots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917158c2",
   "metadata": {},
   "source": [
    "## 7) Decision-Making Policy — Three Options\n",
    "\n",
    "### A) Rules (Baseline)\n",
    "Simple if-then logic to ask for missing slots in order.\n",
    "\n",
    "### B) Bandit (Thompson Sampling)\n",
    "**Why:** Learn which follow-up question works best over time (no manual ordering).\n",
    "**Reward:** Fast resolution, fewer turns, positive feedback.\n",
    "\n",
    "### C) LLM Planner (Guardrailed)\n",
    "**Why:** Dynamic planning without hard-coded flow; great for exploration.\n",
    "**How:** Provide state to an LLM; it returns a structured action (e.g., `ask(\"fan_noise\")` or `solve()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- A) Rules ---\n",
    "def next_question_rules(intent: Optional[str], slots: Dict[str, str]) -> Optional[str]:\n",
    "    if not intent:\n",
    "        return \"Is it overheating, slow performance, battery, network, or an update problem?\"\n",
    "    required = REQUIRED_SLOTS.get(intent, [])\n",
    "    missing = [s for s in required if s not in slots or not slots[s]]\n",
    "    return SLOT_QUESTIONS[missing[0]] if missing else None\n",
    "\n",
    "# --- B) Bandit (Thompson Sampling) ---\n",
    "bandit_params = defaultdict(lambda: {\"a\": 1, \"b\": 1})  # Beta prior per intent:slot\n",
    "\n",
    "def thompson_select(intent: str, slots: Dict[str, str]) -> Optional[str]:\n",
    "    candidates = REQUIRED_SLOTS.get(intent, [])\n",
    "    remaining = [s for s in candidates if s not in slots or not slots[s]]\n",
    "    if not remaining:\n",
    "        return None\n",
    "    \n",
    "    sampled = []\n",
    "    for s in remaining:\n",
    "        key = f\"{intent}:{s}\"\n",
    "        a, b = bandit_params[key][\"a\"], bandit_params[key][\"b\"]\n",
    "        sampled.append((random.betavariate(a, b), s))\n",
    "    \n",
    "    sampled.sort(reverse=True)\n",
    "    chosen_slot = sampled[0][1]\n",
    "    return SLOT_QUESTIONS[chosen_slot]\n",
    "\n",
    "def update_bandit(intent: str, slot_name: str, reward: float):\n",
    "    key = f\"{intent}:{slot_name}\"\n",
    "    if reward >= 0.5:\n",
    "        bandit_params[key][\"a\"] += 1\n",
    "    else:\n",
    "        bandit_params[key][\"b\"] += 1\n",
    "\n",
    "# --- C) LLM Planner (Stub) ---\n",
    "def llm_plan_next(intent: Optional[str], slots: Dict[str, str], sentiment_label: str, turn: int) -> str:\n",
    "    \"\"\"\n",
    "    Pseudocode stub. In a real system, call your LLM with a system prompt:\n",
    "    - Tools: ask(slot), solve(), escalate()\n",
    "    - Guardrails: ask at most one follow-up; escalate if sentiment very negative and confidence low.\n",
    "    - State: intent, missing slots, sentiment, turn count.\n",
    "    Return a string action like: 'ASK:fan_noise' or 'SOLVE' or 'ESCALATE'.\n",
    "    \"\"\"\n",
    "    if not intent:\n",
    "        return \"ASK:intent_clarification\"\n",
    "    \n",
    "    required = REQUIRED_SLOTS.get(intent, [])\n",
    "    missing = [s for s in required if s not in slots or not slots[s]]\n",
    "    \n",
    "    if missing:\n",
    "        # Simple heuristic for the stub: just ask the first missing one\n",
    "        return f\"ASK:{missing[0]}\"\n",
    "    else:\n",
    "        return \"SOLVE\"\n",
    "\n",
    "# --- Selector ---\n",
    "def select_next_step(intent: Optional[str], slots: Dict[str, str], method_policy: str, turn: int, sentiment_label: str) -> Optional[str]:\n",
    "    if method_policy == \"rules\":\n",
    "        return next_question_rules(intent, slots)\n",
    "    elif method_policy == \"bandit\":\n",
    "        return thompson_select(intent, slots)\n",
    "    elif method_policy == \"llm_planner\":\n",
    "        action = llm_plan_next(intent, slots, sentiment_label, turn)\n",
    "        if action.startswith(\"ASK:\"):\n",
    "            slot = action.split(\":\", 1)[1]\n",
    "            return SLOT_QUESTIONS.get(slot, \"Could you share more details?\")\n",
    "        elif action == \"SOLVE\":\n",
    "            return None\n",
    "        else:\n",
    "            return \"Escalating to human support.\"\n",
    "    else:\n",
    "        return \"Method policy not recognized.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd0a6e",
   "metadata": {},
   "source": [
    "## 8) Solution Templates (Tailored Steps)\n",
    "Once enough slots are filled (or the planner decides), we provide a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918205fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(intent: Optional[str], slots: Dict[str, str]) -> str:\n",
    "    if intent == \"overheating\":\n",
    "        steps = [\n",
    "            \"Ensure vents are unobstructed; use the laptop on a hard surface.\",\n",
    "            \"Clean dust from fans/vents; consider compressed air.\",\n",
    "            \"Open Task Manager → sort by CPU/GPU; close heavy background apps.\",\n",
    "            \"Update OEM BIOS/firmware and thermal management drivers.\",\n",
    "        ]\n",
    "        if slots.get(\"is_after_update\") == \"yes\":\n",
    "            steps.insert(2, \"If started after an update: roll back that update or reinstall thermal drivers.\")\n",
    "        return \"Troubleshooting steps for overheating:\\n\" + \"\\n\".join(steps)\n",
    "    \n",
    "    elif intent == \"slow_performance\":\n",
    "        return (\n",
    "            \"Troubleshooting steps for slow performance:\\n\"\n",
    "            \"1) Check CPU/RAM/Disk in Task Manager; identify top processes.\\n\"\n",
    "            \"2) Scan for malware; ensure Defender signatures are current.\\n\"\n",
    "            \"3) Disable startup apps; check indexing and background updates.\\n\"\n",
    "            \"4) Verify drivers and updates; roll back recent changes if needed.\\n\"\n",
    "            \"5) Check thermal throttling; clean fans and ensure good ventilation.\"\n",
    "        )\n",
    "    \n",
    "    elif intent == \"update_issue\":\n",
    "        return (\n",
    "            \"Troubleshooting steps for update issues:\\n\"\n",
    "            \"1) Identify update build/version; check known issues.\\n\"\n",
    "            \"2) Roll back or uninstall problematic update.\\n\"\n",
    "            \"3) Reinstall OEM drivers (chipset/thermal/graphics).\\n\"\n",
    "            \"4) Check Event Viewer for error codes; share any logs.\\n\"\n",
    "            \"5) Pause updates temporarily; retry after cleanup.\"\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        return \"I have a hypothesis but need a bit more information to be sure. Please contact support.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ee687",
   "metadata": {},
   "source": [
    "## 9) Telemetry (Learning from Data) — Where & How\n",
    "We simulate logging conversation turns and outcomes into JSONL.\n",
    "\n",
    "**Privacy note:** Log intent/slots/outcome, not raw user text, to minimize PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e2fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_event(event: Dict):\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(event) + \"\\n\")\n",
    "\n",
    "def reward_from_outcome(resolved: bool, turns: int, feedback_sentiment: Optional[str]) -> float:\n",
    "    \"\"\"\n",
    "    Simple reward shaping:\n",
    "    +1.0 for resolved\n",
    "    -0.05 per turn\n",
    "    +0.2 if feedback is positive\n",
    "    \"\"\"\n",
    "    r = 1.0 if resolved else 0.0\n",
    "    r -= 0.05 * max(turns - 1, 0)\n",
    "    if feedback_sentiment == \"POSITIVE\":\n",
    "        r += 0.2\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b3724",
   "metadata": {},
   "source": [
    "## 10) Putting It All Together (Single-turn Demo + Follow-ups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d21bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialogue state\n",
    "turn = 0\n",
    "sent_label = sent[\"label\"]  # initial sentiment on query\n",
    "\n",
    "print(f\"User Query: {query}\")\n",
    "print(f\"Detected Intent: {intent}\")\n",
    "\n",
    "# Ask follow-ups until slots are complete (or planner decides to solve)\n",
    "while True:\n",
    "    turn += 1\n",
    "    question = select_next_step(intent, slots, METHOD_POLICY, turn, sent_label)\n",
    "    \n",
    "    if question is None:\n",
    "        # Solve\n",
    "        solution = solve(intent, slots)\n",
    "        print(\"\\n=== Solution ===\\n\", solution)\n",
    "        break\n",
    "    else:\n",
    "        print(f\"\\nQ{turn}: {question}\")\n",
    "        # Simulate user's answer (in a real app: capture input)\n",
    "        # For demo, we auto-fill a plausible answer:\n",
    "        if \"update\" in question:\n",
    "            slots[\"is_after_update\"] = \"yes\"\n",
    "        elif \"fan\" in question:\n",
    "            slots[\"fan_noise\"] = \"yes\"\n",
    "        elif \"When did\" in question:\n",
    "            slots[\"when_started\"] = \"yesterday\"\n",
    "        elif \"room temperature\" in question:\n",
    "            slots[\"ambient_temp\"] = \"no\"\n",
    "        elif \"error codes\" in question:\n",
    "            slots[\"error_codes\"] = \"none\"\n",
    "        else:\n",
    "            # generic fill\n",
    "            slots_key = next((k for k,v in SLOT_QUESTIONS.items() if v == question), None)\n",
    "            if slots_key:\n",
    "                slots[slots_key] = \"yes\"\n",
    "        \n",
    "        print(f\"(User answers... filling slot)\")\n",
    "\n",
    "# ----- Collect feedback -----\n",
    "user_feedback = \"Thanks, this resolved my issue quickly.\"\n",
    "feedback = sentiment(user_feedback)[0]\n",
    "print(\"\\nFeedback sentiment:\", feedback)\n",
    "\n",
    "# ----- Log event & update bandit -----\n",
    "resolved = True\n",
    "event = {\n",
    "    \"intent\": intent,\n",
    "    \"slots_filled\": [k for k in slots.keys()],\n",
    "    \"policy\": METHOD_POLICY,\n",
    "    \"turns\": turn,\n",
    "    \"resolved\": resolved,\n",
    "    \"feedback_sentiment\": feedback[\"label\"]\n",
    "}\n",
    "log_event(event)\n",
    "\n",
    "# Reward learning (only meaningful for bandits)\n",
    "if METHOD_POLICY == \"bandit\":\n",
    "    # Reward the *last* asked slot as a toy proxy\n",
    "    last_slot = event[\"slots_filled\"][-1] if event[\"slots_filled\"] else None\n",
    "    if last_slot:\n",
    "        r = reward_from_outcome(resolved, turn, feedback[\"label\"])\n",
    "        update_bandit(intent, last_slot, r)\n",
    "        print(f\"Bandit updated for {intent}:{last_slot} with reward {round(r,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8d0bd",
   "metadata": {},
   "source": [
    "## 11) Theory Recap (Cheat Sheet)\n",
    "\n",
    "*   **Tokenization:**\n",
    "    *   NLTK: word-level (for learning).\n",
    "    *   Transformers: subword; always use the model’s tokenizer before feeding models.\n",
    "*   **NER & POS:** Context-aware via transformers; better than rule-based for real text.\n",
    "*   **Sentiment:** Guides empathy and escalation logic.\n",
    "*   **Intent:**\n",
    "    *   Zero-shot (fast start, no labels).\n",
    "    *   LogReg (learn from labeled examples; teaches ML fundamentals).\n",
    "*   **Policy:**\n",
    "    *   Rules (baseline, predictable).\n",
    "    *   Bandits (Thompson Sampling): Learn best next question per context; update with rewards from telemetry.\n",
    "    *   LLM Planner: Delegate decision-making to an LLM with guardrails; great for iterative exploration.\n",
    "*   **Learning from data:**\n",
    "    *   Store compact conversation outcomes (intent, slots, turns, success, feedback sentiment).\n",
    "    *   Update bandit/RL policies from historical logs; fine-tune models later if needed.\n",
    "    *   Prioritize privacy & security by minimizing raw text in logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949bf4d",
   "metadata": {},
   "source": [
    "## 12) Extensions (Next Steps)\n",
    "\n",
    "*   **RAG (Retrieval-Augmented Generation):** Use intent + slots to query a KB and summarize with citations.\n",
    "*   **Offline RL:** Train a multi-turn policy (states, actions, rewards) from logs.\n",
    "*   **Evaluation:** Track resolution rate, average turns, CSAT proxy (feedback sentiment).\n",
    "*   **Guardrails:** Limit follow-ups; escalate under low confidence + negative sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
