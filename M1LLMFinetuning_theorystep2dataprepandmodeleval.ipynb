{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a8ab45",
   "metadata": {},
   "source": [
    "# Fine-Tuning Techniques for Customer Support Summarization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Fine-tuning a pretrained large language model (LLM) is a practical way to turn a general model into a specialist. In this notebook we adapt a seq2seq model so it can summarize customer-support style chats (similar to finance-service escalations) with accuracy and clarity. The workflow mirrors any domain adaptation effort: understand the task, collect representative data, clean and tokenize it, fine-tune the model, then evaluate and iterate.\n",
    "\n",
    "By the end of this reading you will be able to:\n",
    "\n",
    "- Define task-specific requirements for fine-tuning an LLM on chat-style summaries.\n",
    "- Collect (or download) and preprocess a dialogue dataset so it matches the model inputs.\n",
    "- Fine-tune a pretrained summarization model on the SAMSum corpus (a stand-in for customer-service transcripts).\n",
    "- Evaluate and optimize the fine-tuned model with ROUGE so you know when it is ready for production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca425f4",
   "metadata": {},
   "source": [
    "## Step-by-Step Guide to Fine-Tuning an LLM\n",
    "\n",
    "We follow six core steps. Additional sub-sections expand on the \"how\" for each step, but keep these main stages in mind:\n",
    "\n",
    "1. **Step 1 – Understand the Task:** Clarify the objective, labels, and domain (customer-support chat summaries).\n",
    "2. **Step 2 – Collect the Dataset:** Acquire dialogue data that mirrors production traffic (SAMSum or your internal chats).\n",
    "3. **Step 3 – Preprocess the Data:** Clean, tokenize, verify sequence lengths, and create any helper splits.\n",
    "4. **Step 4 – Fine-Tune the Pretrained Model:** Load FLAN-T5, configure training arguments, and run Seq2Seq training.\n",
    "5. **Step 5 – Evaluate the Fine-Tuned Model:** Use ROUGE (or accuracy/precision/recall for classification) on the validation/test sets.\n",
    "6. **Step 6 – Optimize the Model:** Tune hyperparameters or apply augmentation techniques to push performance further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6fcc66",
   "metadata": {},
   "source": [
    "## Step 1: Understand the Task\n",
    "\n",
    "- **Task definition:** Abstractive summarization of informal customer-support style chats. The model outputs a concise synopsis that triage teams can read quickly.\n",
    "- **Domain context:** Conversations include multiple speakers, shorthand, emojis, and domain terms (e.g., finance accounts, refunds, shipping). We preserve speaker tags because they provide structure.\n",
    "- **Success criteria:** High ROUGE scores plus qualitative readability (support leads can trust the summaries).\n",
    "- **Why this matters:** Without a crisp task definition, it is impossible to pick the right data, prompts, or evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e33fa",
   "metadata": {},
   "source": [
    "> ## Step 2: Collect the Dataset\n",
    " >\n",
    "> - **Primary source:** [SAMSum](https://huggingface.co/datasets/samsum) – 16k messenger-like chats with human-written summaries.\n",
    " > - **Why SAMSum?** It mirrors the tone, pace, and multi-speaker structure of real customer-service escalations, so it is a strong public proxy for finance/contact-center data.\n",
    " > - **Enterprise alternative:** Replace SAMSum with anonymized internal chat logs labeled with the summaries or categories you care about.\n",
    " > - **Learner action:** If `load_dataset(\"samsum\")` is blocked, download `train.json`, `validation.json`, and `test.json` from the \"Files\" tab and point the code to your local directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9070614",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess the Data\n",
    "\n",
    "Preprocessing ensures the raw dialogues match what the model expects.\n",
    "\n",
    "1. **Load & Inspect:** Use the `datasets` library to pull SAMSum (or your local JSON files). Immediately inspect a record so stakeholders can confirm the format.\n",
    "2. **Tokenize:** Convert dialogues and summaries into `input_ids`, `attention_mask`, and `labels` using the FLAN-T5 tokenizer. We prepend \"summarize:\" so the model knows the intent.\n",
    "3. **Verify Splits:** SAMSum already includes train/validation/test partitions. The next code cell prints their sizes and a sample dialogue to confirm the metadata.\n",
    "4. **Check Sequence Lengths:** Plot histograms to ensure your `max_length` choices (512 for dialogues, 128 for summaries) avoid excessive truncation.\n",
    "5. **Optional Augmentation:** Techniques such as synonym replacement (NLTK WordNet example below) or back-translation add mild variation when data is scarce.\n",
    "\n",
    "These sub-steps feed the fine-tuning pipeline with clean, well-structured tensors instead of raw text blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d667c0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: py7zr in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: anyio in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: texttable in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.20.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (3.23.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (1.2.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (7.1.0)\n",
      "Requirement already satisfied: pyzstd>=0.16.1 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (0.18.0)\n",
      "Requirement already satisfied: pyppmd<1.3.0,>=1.1.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (1.2.0)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (1.0.7)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (0.2.3)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py7zr) (1.0.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rouge_score) (2.3.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rouge_score) (3.9.2)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: click in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk->rouge_score) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk->rouge_score) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk->rouge_score) (2025.11.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amansahni\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amansahni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: knkarthick/samsum\n",
      "Tip: if you see an auth error, run `huggingface-cli login` in a terminal once.\n",
      "Training samples: 14731\n",
      "Sample Dialogue:\n",
      "Amanda: I baked  cookies. Do you want some?\n",
      "Jerry: Sure!\n",
      "Amanda: I'll bring you tomorrow :-)\n",
      "Sample Summary:\n",
      "Amanda baked cookies and will bring Jerry some tomorrow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 818/818 [00:00<00:00, 6144.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data tokenized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Install/upgrade the core libraries used throughout the notebook\n",
    "%pip install --upgrade datasets py7zr evaluate rouge_score\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# --- Step 1: Load the SAMSum dataset ---\n",
    "dataset_id = \"knkarthick/samsum\"  # mirror of SAMSum that often stays available\n",
    "print(f\"Loading dataset: {dataset_id}\")\n",
    "print(\"Tip: if you see an auth error, run `huggingface-cli login` in a terminal once.\")\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset(dataset_id)\n",
    "except Exception as err:\n",
    "    print(f\"Remote download failed: {err}\")\n",
    "    print(\"Falling back to local JSON files. Download train/validation/test from the dataset page if needed.\")\n",
    "    local_data_dir = Path(\"c:/data/samsum\")\n",
    "    dataset = load_dataset(\n",
    "        \"json\",\n",
    "        data_files={\n",
    "            \"train\": str(local_data_dir / \"train.json\"),\n",
    "            \"validation\": str(local_data_dir / \"validation.json\"),\n",
    "            \"test\": str(local_data_dir / \"test.json\"),\n",
    "        },\n",
    "    )\n",
    "    print(f\"Loaded SAMSum from local folder: {local_data_dir}\")\n",
    "\n",
    "print(f\"Training samples: {len(dataset['train'])}\")\n",
    "print(f\"Sample Dialogue:\\n{dataset['train'][0]['dialogue']}\")\n",
    "print(f\"Sample Summary:\\n{dataset['train'][0]['summary']}\")\n",
    "\n",
    "# --- Step 2: Initialize the tokenizer ---\n",
    "model_checkpoint = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# --- Step 3: Tokenize dialogues and summaries ---\n",
    "def preprocess_function(examples):\n",
    "    inputs = [\"summarize: \" + doc for doc in examples[\"dialogue\"]]  # keep speaker turns intact\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "print(\"\\nData tokenized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275aaab",
   "metadata": {},
   "source": [
    "### 3.1 Verify the Built-in Splits\n",
    "\n",
    "SAMSum already includes three partitions, so there is no need to reshuffle:\n",
    "\n",
    "- **Train:** Used to update model weights.\n",
    "- **Validation:** Used for metric tracking during training (early stopping, hyperparameter tweaks).\n",
    "- **Test:** Held out until the very end for unbiased reporting.\n",
    "\n",
    "The code right after this cell prints the record counts and shows a sample dialogue/summary pair so you can double-check the data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b39f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train      : 14731 conversations\n",
      "Validation :   818 conversations\n",
      "Test       :   819 conversations\n",
      "\n",
      "Sample dialogue:\n",
      "Amanda: I baked  cookies. Do you want some?\n",
      "Jerry: Sure!\n",
      "Amanda: I'll bring you tomorrow :-)\n",
      "\n",
      "Reference summary:\n",
      "Amanda baked cookies and will bring Jerry some tomorrow.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the ready-made splits to build intuition\n",
    "split_lengths = {split: len(dataset[split]) for split in dataset.keys()}\n",
    "for split_name, length in split_lengths.items():\n",
    "    print(f\"{split_name.title():<11}: {length:>5} conversations\")\n",
    "\n",
    "example = dataset[\"train\"][0]\n",
    "print(\"\\nSample dialogue:\")\n",
    "print(example[\"dialogue\"])\n",
    "print(\"\\nReference summary:\")\n",
    "print(example[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab7371",
   "metadata": {},
   "source": [
    "### 3.2 Analyze Sequence Lengths\n",
    "\n",
    "Summarization succeeds only if the model sees complete dialogues and concise targets.\n",
    "\n",
    "- **Why check lengths?** Dialogues longer than `max_length=512` get truncated; summaries longer than 128 tokens slow training.\n",
    "- **What to look for?** Long tails in the histogram that might justify higher cutoffs or chunking.\n",
    "- **Action:** Use the matplotlib chart in the next cell to confirm most customer chats fit inside the window. Adjust `max_length` if needed before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18bd661f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Dialogue Length: 803\n",
      "Max Summary Length: 64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate lengths of dialogues in the training set\n",
    "dialogue_lengths = [len(x.split()) for x in dataset['train']['dialogue']]\n",
    "summary_lengths = [len(x.split()) for x in dataset['train']['summary']]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(dialogue_lengths, bins=50, color='blue', alpha=0.7)\n",
    "axes[0].set_title('Dialogue Length Distribution')\n",
    "axes[0].set_xlabel('Word Count')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].hist(summary_lengths, bins=50, color='green', alpha=0.7)\n",
    "axes[1].set_title('Summary Length Distribution')\n",
    "axes[1].set_xlabel('Word Count')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Max Dialogue Length: {max(dialogue_lengths)}\")\n",
    "print(f\"Max Summary Length: {max(summary_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac745d97",
   "metadata": {},
   "source": [
    "### 3.3 Optional Data Augmentation\n",
    "\n",
    "When the dataset is small, light-touch augmentation keeps the model from overfitting to exact phrasing.\n",
    "\n",
    "- **Purpose:** Give the model paraphrased wording while preserving intent.\n",
    "- **Options:** Synonym replacement (shown below with NLTK WordNet), back-translation, or prompt-based paraphrases from another LLM.\n",
    "- **Best practice:** Keep changes subtle so the summary label is still correct.\n",
    "\n",
    "The accompanying code picks random tokens and swaps them with WordNet synonyms—perfect for quick experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4501be23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : The customer service was excellent and very helpful.\n",
      "Augmented: The customer service was first-class and identical helpful.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download once per environment (quiet=True keeps the logs clean)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    synonyms.discard(word)\n",
    "    return list(synonyms)\n",
    "\n",
    "def synonym_replacement(text, n=1):\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    candidate_words = [word for word in words if word.isalnum()]\n",
    "    random.shuffle(candidate_words)\n",
    "\n",
    "    replacements = 0\n",
    "    for word in candidate_words:\n",
    "        synonyms = get_synonyms(word)\n",
    "        if synonyms:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = [synonym if w == word else w for w in new_words]\n",
    "            replacements += 1\n",
    "        if replacements >= n:\n",
    "            break\n",
    "\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "original_text = \"The customer service was excellent and very helpful.\"\n",
    "augmented_text = synonym_replacement(original_text, n=2)\n",
    "\n",
    "print(f\"Original : {original_text}\")\n",
    "print(f\"Augmented: {augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c0cf6",
   "metadata": {},
   "source": [
    "## Step 4: Fine-Tune the Pretrained Model\n",
    "\n",
    "Now that the data is tokenized, connect it to a generation-capable backbone.\n",
    "\n",
    "- **Model choice:** `google/flan-t5-small` keeps training fast while supporting instruction-style prompts like \"summarize:\".\n",
    "- **Why Seq2Seq?** Summarization requires the model to generate free-form text, not pick a class label.\n",
    "- **Core ingredients:**\n",
    "  1. `AutoModelForSeq2SeqLM` for the architecture.\n",
    "  2. `Seq2SeqTrainingArguments` to define epochs, learning rate, batch size, and evaluation cadence.\n",
    "  3. `DataCollatorForSeq2Seq` to dynamically pad batches (saves memory).\n",
    "- **Learner action:** Review the next code cell and adjust hyperparameters (epochs, batch size, fp16) to match your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e99d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\amansahni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amansahni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\amansahni\\.cache\\huggingface\\hub\\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "\n",
    "# 1. Load Model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "# 2. Define Arguments\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"samsum-model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,  # Smaller batch size for generation tasks\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,    # Essential for calculating ROUGE during training\n",
    "    fp16=False,                    # Set to True if using GPU\n",
    ")\n",
    "\n",
    "# 3. Data Collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# 4. Initialize Trainer (Conceptual - requires compute_metrics defined below)\n",
    "# trainer = Seq2SeqTrainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     data_collator=data_collator,\n",
    "#     tokenizer=tokenizer,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ab4ba",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Fine-Tuned Model\n",
    "\n",
    "Evaluation tells you whether the model generalizes beyond the training chats.\n",
    "\n",
    "- **Primary metric:** ROUGE (1, 2, L) measures token overlap between generated and reference summaries. Higher is better.\n",
    "- **Why not accuracy?** Summaries are free-form text; overlap-based metrics capture fluency better than exact matches.\n",
    "- **Process:**\n",
    "  1. Generate summaries on the validation/test split (`predict_with_generate=True`).\n",
    "  2. Decode predictions and references back into text.\n",
    "  3. Compute ROUGE via the `evaluate` library and monitor length statistics (`gen_len`).\n",
    "- **Learner action:** Run the next code cell after training to quantify improvements; compare against baselines such as \"copy the first sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Decode generated summaries\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute ROUGE\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    \n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "# Now you would pass this to the Seq2SeqTrainer:\n",
    "# trainer = Seq2SeqTrainer(..., compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a92159",
   "metadata": {},
   "source": [
    "## Step 6: Optimize the Fine-Tuned Model\n",
    "\n",
    "Once you get a baseline ROUGE score, keep improving the model with **small, controlled experiments**. Optimization is just a structured way of answering two questions:\n",
    "\n",
    "1. *Can I tweak the training recipe?* (learning rate, batch size, epochs, label smoothing, etc.)\n",
    "2. *Can I give the model slightly better data?* (augment rare patterns, add more chats, balance categories).\n",
    "\n",
    "### Easy Optimization Checklist\n",
    "\n",
    "- **Learning rate sweeps:** Try `1e-4`, `5e-5`, `2e-5` and see which keeps validation ROUGE highest.\n",
    "- **Epoch budgeting:** Short chats often converge in 2–4 epochs; monitor when validation ROUGE stops rising.\n",
    "- **Batch size vs. memory:** Increase batch size if you have GPU headroom; otherwise keep it small and accumulate gradients.\n",
    "- **Light augmentation:** Re-run training with the synonym/back-translation tricks from Step 3.3 to see if generalization improves.\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "These adjustments prevent overfitting (memorizing training chats) and ensure the model performs well on new finance-support transcripts. The small code example below shows two ways to run experiments: a manual loop and the built-in `hyperparameter_search` helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# --- Manual mini-grid search --------------------------------------------------\n",
    "grid_configs = [\n",
    "    {\"learning_rate\": 2e-5, \"num_train_epochs\": 3, \"per_device_train_batch_size\": 8},\n",
    "    {\"learning_rate\": 1e-4, \"num_train_epochs\": 2, \"per_device_train_batch_size\": 8},\n",
    "    {\"learning_rate\": 5e-5, \"num_train_epochs\": 4, \"per_device_train_batch_size\": 4},\n",
    "]\n",
    "\n",
    "manual_results = []\n",
    "for trial_id, cfg in enumerate(grid_configs, start=1):\n",
    "    trial_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=f\"samsum-model-trial-{trial_id}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=cfg[\"learning_rate\"],\n",
    "        per_device_train_batch_size=cfg[\"per_device_train_batch_size\"],\n",
    "        per_device_eval_batch_size=cfg[\"per_device_train_batch_size\"],\n",
    "        num_train_epochs=cfg[\"num_train_epochs\"],\n",
    "        weight_decay=0.01,\n",
    "        predict_with_generate=True,\n",
    "        fp16=False,\n",
    "        save_total_limit=1,\n",
    "        logging_steps=25,\n",
    "    )\n",
    "    trial_trainer = Seq2SeqTrainer(\n",
    "        model=deepcopy(model),\n",
    "        args=trial_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    print(f\"\\nTrial {trial_id}: {cfg}\")\n",
    "    train_output = trial_trainer.train()  # runs a short training session\n",
    "    eval_metrics = trial_trainer.evaluate()\n",
    "    manual_results.append({\"config\": cfg, \"metrics\": eval_metrics})\n",
    "    print(f\"Validation ROUGE-L: {eval_metrics.get('eval_rougeL', 'n/a'):.4f}\")\n",
    "\n",
    "print(\"\\nManual search summary:\")\n",
    "for result in manual_results:\n",
    "    print(result)\n",
    "\n",
    "# --- Automated hyperparameter search (Optuna/Ray Tune friendly) --------------\n",
    "# Reuse a base trainer (for example the one defined in Step 4) and let it explore automatically.\n",
    "# Note: requires `pip install optuna` or `pip install ray[tune]` depending on backend.\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "base_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"samsum-model-hp\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=25,\n",
    "    report_to=None,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rougeL\",\n",
    "    greater_is_better=True,\n",
    " )\n",
    "\n",
    "base_trainer = Seq2SeqTrainer(\n",
    "    model_init=model_init,\n",
    "    args=base_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    " )\n",
    "\n",
    "best_run = base_trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    n_trials=4,\n",
    "    hp_space=lambda _: {\n",
    "        \"learning_rate\": tune.loguniform(1e-5, 1e-3),\n",
    "        \"num_train_epochs\": tune.randint(2, 5),\n",
    "        \"per_device_train_batch_size\": tune.choice([4, 8, 16]),\n",
    "    },\n",
    " )\n",
    "print(\"\\nBest run:\", best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51f704",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Accurate fine-tuning follows a repeatable pattern: define the task, gather representative chats, preprocess them carefully, fine-tune a pretrained model, evaluate with the right metrics, and optimize iteratively. With SAMSum as a stand-in for finance/customer-service interactions, you now have a template that balances theory (the *why*) and practice (the *how*). Apply the same six steps to your internal data and you will build reliable, domain-aware summarization assistants."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
