{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb1ce95",
   "metadata": {},
   "source": [
    "# ðŸ¦œ Wood Pecker Retail Chatbot: Student Guide\n",
    "\n",
    "**Welcome!** This notebook is a hands-on tutorial for building a retail chatbot. \n",
    "\n",
    "You will explore two different ways to build chat logic:\n",
    "1.  **Manual Rules (The \"Reliable\" Way):** Using keywords to give exact, pre-written answers.\n",
    "2.  **NLP Pipeline (The \"Smart\" Way):** Using AI to understand sentence structure, entities, and sentiment.\n",
    "\n",
    "By the end, you'll have a working chatbot UI you can talk to!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05ed5e",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Goals\n",
    "\n",
    "*   **Understand Rule-Based Logic:** See how simple keyword matching can solve 80% of customer support queries.\n",
    "*   **Explore NLP Concepts:** Peek \"under the hood\" of AI to see how it breaks down text into **Tokens**, **Parts of Speech**, and **Entities**.\n",
    "*   **Build a UI:** Use the `Gradio` library to launch a real web interface for your bot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f923968",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Project Blueprint\n",
    "\n",
    "We will build this in **4 steps**:\n",
    "\n",
    "1.  **The Knowledge Base**: Define a list of common questions (FAQs) and their answers.\n",
    "2.  **The Brain**: Write a Python class that matches user questions to our FAQs using keywords.\n",
    "3.  **The NLP Lab**: Set up advanced tools (spaCy, Transformers) to analyze text for sentiment and entities.\n",
    "4.  **The Interface**: Connect everything to a chat window so we can test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1348999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal dependency check: Gradio gives us a quick UI without extra frontend tooling.\n",
    "import importlib  # Used to check if a library is installed\n",
    "import subprocess  # Used to run shell commands (like pip install)\n",
    "import sys  # Used to access system-specific parameters (like the python executable path)\n",
    "\n",
    "\n",
    "def ensure(package: str) -> None:\n",
    "    \"\"\"Install `package` via pip if it is missing.\"\"\"\n",
    "    if importlib.util.find_spec(package) is None:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "\n",
    "ensure(\"gradio\")\n",
    "ensure(\"transformers\")\n",
    "ensure(\"torch\")  # PyTorch is the engine behind these Transformers models\n",
    "\n",
    "import gradio as gr  # Gradio: A library for creating machine learning demos and web UIs quickly\n",
    "from transformers import pipeline, AutoTokenizer  # Transformers: The library for BERT, GPT, etc.\n",
    "\n",
    "GREETING_MESSAGE = \"Hello, how can I help you today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29382052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT models... this may take a minute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amansahni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\amansahni\\.cache\\huggingface\\hub\\models--vblagoje--bert-english-uncased-finetuned-pos. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "c:\\Users\\amansahni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\amansahni\\.cache\\huggingface\\hub\\models--dslim--bert-base-NER. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\amansahni\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\amansahni\\.cache\\huggingface\\hub\\models--dslim--bert-base-NER. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers BERT components loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading BERT models... this may take a minute...\")\n",
    "\n",
    "# --- 1. Tokenizer (BERT Base) ---\n",
    "# BERT sees text as \"sub-words\" (tokens). We load the standard tokenizer.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# --- 2. POS Tagging (BERT fine-tuned) ---\n",
    "# A BERT model fine-tuned to identify Nouns, Verbs, Adjectives, etc.\n",
    "# Model: vblagoje/bert-english-uncased-finetuned-pos\n",
    "try:\n",
    "    pos_pipeline = pipeline(\"token-classification\", model=\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load POS model: {e}\")\n",
    "    pos_pipeline = None\n",
    "\n",
    "# --- 3. NER (BERT fine-tuned) ---\n",
    "# A BERT model fine-tuned to find Persons, Locations, Organizations (CoNLL-2003 dataset).\n",
    "# Model: dslim/bert-base-NER\n",
    "try:\n",
    "    ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load NER model: {e}\")\n",
    "    ner_pipeline = None\n",
    "\n",
    "# --- 4. Sentiment (DistilBERT) ---\n",
    "# A lighter BERT model fine-tuned for positive/negative sentiment.\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    ")\n",
    "\n",
    "print(\"Transformers BERT components loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf46a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime  # Used for handling date and time objects (e.g., timestamps)\n",
    "\n",
    "faq_items = [\n",
    "    {\n",
    "        \"question\": \"What are your store hours?\",\n",
    "        \"answer\": \"We are open 10 AM - 8 PM Monday through Saturday, and 11 AM - 6 PM on Sundays.\",\n",
    "        \"keywords\": [\"hours\", \"open\", \"close\", \"time\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Where is the store located?\",\n",
    "        \"answer\": \"Wood Pecker is inside the Riverwalk Mall, first floor near the fountain.\",\n",
    "        \"keywords\": [\"where\", \"location\", \"address\", \"store\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Do you offer curbside pickup?\",\n",
    "        \"answer\": \"Yes, select curbside pickup at checkout and call us when you arrive at bay C.\",\n",
    "        \"keywords\": [\"curbside\", \"pickup\", \"collect\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can I check my order status?\",\n",
    "        \"answer\": \"Go to woodpecker.com/orders and enter your email plus order number to see live status.\",\n",
    "        \"keywords\": [\"order\", \"status\", \"track\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the shipping options?\",\n",
    "        \"answer\": \"Standard (5-7 days), Expedited (2-3 days), and Overnight are available at checkout.\",\n",
    "        \"keywords\": [\"shipping\", \"delivery\", \"ship\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How long does shipping take?\",\n",
    "        \"answer\": \"Standard shipping arrives within 5-7 business days; peak holidays may add a day.\",\n",
    "        \"keywords\": [\"how long\", \"shipping\", \"arrive\", \"time\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Can I change my shipping address after ordering?\",\n",
    "        \"answer\": \"We can update the address within 30 minutes of purchaseâ€”contact support via chat or phone.\",\n",
    "        \"keywords\": [\"change\", \"address\", \"order\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Do you have any sales right now?\",\n",
    "        \"answer\": \"Weekly specials post every Friday on our homepage plus 15% off clearance in-store.\",\n",
    "        \"keywords\": [\"sale\", \"discount\", \"deal\", \"promo\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do returns work?\",\n",
    "        \"answer\": \"Returns are free within 30 days with receipt; bring the item or ship it back with the prepaid label.\",\n",
    "        \"keywords\": [\"return\", \"policy\", \"refund\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Can I exchange a gift?\",\n",
    "        \"answer\": \"Absolutelyâ€”bring the gift receipt or sender name within 60 days for an exchange or store credit.\",\n",
    "        \"keywords\": [\"exchange\", \"gift\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Do you sell gift cards?\",\n",
    "        \"answer\": \"Gift cards are available from $10 to $500 both online and at the register.\",\n",
    "        \"keywords\": [\"gift\", \"card\", \"voucher\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I apply a promo code?\",\n",
    "        \"answer\": \"Enter the code in the Promo Code box at checkout; it will show the discount instantly.\",\n",
    "        \"keywords\": [\"promo\", \"code\", \"coupon\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What sizes do you carry?\",\n",
    "        \"answer\": \"Most apparel ranges from XS-3XL, and footwear spans sizes 5-13 for adults.\",\n",
    "        \"keywords\": [\"size\", \"sizing\", \"fit\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Is there a loyalty program?\",\n",
    "        \"answer\": \"Yesâ€”Woodland Rewards gives 1 point per dollar and $5 back for every 100 points.\",\n",
    "        \"keywords\": [\"loyalty\", \"membership\", \"rewards\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Can I talk to a human agent?\",\n",
    "        \"answer\": \"Sure thing. Call 800-555-7425 or use the Help > Live Chat option for a teammate.\",\n",
    "        \"keywords\": [\"agent\", \"human\", \"representative\", \"contact\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Do you offer repairs or alterations?\",\n",
    "        \"answer\": \"Basic hemming and zipper repairs are available for $15â€”drop items at the service desk.\",\n",
    "        \"keywords\": [\"repair\", \"alteration\", \"tailor\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I cancel an order?\",\n",
    "        \"answer\": \"You can cancel within 30 minutes via your order page or by calling customer care.\",\n",
    "        \"keywords\": [\"cancel\", \"order\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Are holiday items in stock?\",\n",
    "        \"answer\": \"Seasonal decor is refreshed every Thursday; check the Holiday tab for live inventory badges.\",\n",
    "        \"keywords\": [\"holiday\", \"seasonal\", \"stock\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Do you price match?\",\n",
    "        \"answer\": \"Yes, we match major retailers within 14 days of purchaseâ€”bring the ad or link.\",\n",
    "        \"keywords\": [\"price match\", \"match\", \"price\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What payment methods are accepted?\",\n",
    "        \"answer\": \"We accept major cards, PayPal, Apple Pay, Google Pay, and contactless in-store.\",\n",
    "        \"keywords\": [\"payment\", \"pay\", \"methods\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I get notified about new products?\",\n",
    "        \"answer\": \"Subscribe to our newsletter or enable push alerts in the Wood Pecker mobile app.\",\n",
    "        \"keywords\": [\"notify\", \"new\", \"products\", \"newsletter\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Can I buy online and return in store?\",\n",
    "        \"answer\": \"Yes, bring the packing slip or email receipt to any Wood Pecker location.\",\n",
    "        \"keywords\": [\"buy online\", \"return\", \"store\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Is same-day delivery available?\",\n",
    "        \"answer\": \"Same-day courier delivery is available within 15 miles for $12 on orders placed before 2 PM.\",\n",
    "        \"keywords\": [\"same day\", \"delivery\", \"courier\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Do you have eco-friendly packaging?\",\n",
    "        \"answer\": \"We default to recyclable packaging and offer a $1 rebate when you opt for minimal packing.\",\n",
    "        \"keywords\": [\"eco\", \"sustainable\", \"packaging\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Can I reserve items to try later?\",\n",
    "        \"answer\": \"Use the Reserve & Try feature online to hold items for 24 hours at your chosen store.\",\n",
    "        \"keywords\": [\"reserve\", \"hold\", \"try\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I contact support after hours?\",\n",
    "        \"answer\": \"Leave us a voicemail at 800-555-7425 or email support@woodpecker.comâ€”we reply next morning.\",\n",
    "        \"keywords\": [\"support\", \"after hours\", \"contact\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Where can I see my loyalty balance?\",\n",
    "        \"answer\": \"Log in to your Wood Pecker account and look for the Rewards tab for real-time points.\",\n",
    "        \"keywords\": [\"loyalty\", \"points\", \"balance\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is Wood Pecker's return address?\",\n",
    "        \"answer\": \"Ship returns to Wood Pecker Returns, 422 Orchard Lane, Columbus, OH 43215.\",\n",
    "        \"keywords\": [\"return\", \"address\", \"ship back\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Do you assemble furniture?\",\n",
    "        \"answer\": \"We partner with HandyCo for in-home assembly starting at $49; schedule at checkout.\",\n",
    "        \"keywords\": [\"assemble\", \"assembly\", \"furniture\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6777c3a",
   "metadata": {},
   "source": [
    "## ðŸ§© Understanding the Code Components\n",
    "\n",
    "Before we run the logic, here is a quick guide to the key parts you are about to see:\n",
    "\n",
    "*   **`faq_items`**: A simple list of dictionaries. This is our bot's \"memory\".\n",
    "*   **`SimpleRetailBrain`**: The decision maker. It looks at the user's message, counts how many keywords match an FAQ, and picks the winner.\n",
    "*   **`sentiment_analyzer`**: A pre-trained AI model (from Hugging Face) that detects if a user is happy or frustrated.\n",
    "*   **`analyze_text_simple`**: A teaching function. It takes a sentence and prints out all the NLP data (tokens, nouns, entities) so you can see what the computer \"sees\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec2af8",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Concept Spotlight: BERT Named Entity Recognition (NER)\n",
    "\n",
    "In the **NLP Lab**, we now use a **BERT** model trained on the CoNLL-2003 dataset. \n",
    "\n",
    "Unlike the previous spaCy model, this BERT model focuses on four main entity types:\n",
    "*   **PER**: Person (e.g., \"Serena Williams\")\n",
    "*   **ORG**: Organization (e.g., \"Wood Pecker\", \"Google\")\n",
    "*   **LOC**: Location (e.g., \"Paris\", \"Riverwalk Mall\")\n",
    "*   **MISC**: Miscellaneous (e.g., \"German\", \"Super Bowl\")\n",
    "\n",
    "*Note: BERT uses \"sub-word\" tokenization, so you might see tokens like `##ing` or `##s` in the analysis output!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c0b29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple  # Typing: Provides support for type hints to improve code readability and debugging\n",
    "\n",
    "\n",
    "class SimpleRetailBrain:\n",
    "    \"\"\"Transparent keyword-based router with an optional ML override hook.\"\"\"\n",
    "\n",
    "    def __init__(self, faqs: List[Dict[str, List[str]]]):\n",
    "        self.faqs = faqs\n",
    "        self.ml_handler: Optional[Callable[[str], Optional[str]]] = None\n",
    "\n",
    "    def set_ml_handler(self, handler: Callable[[str], Optional[str]]) -> None:\n",
    "        \"\"\"Allow future ML models (LLMs, vector search, etc.) to override answers.\"\"\"\n",
    "        self.ml_handler = handler\n",
    "\n",
    "    def _score(self, normalized_prompt: str, keywords: List[str]) -> int:\n",
    "        return sum(1 for keyword in keywords if keyword in normalized_prompt)\n",
    "\n",
    "    def answer(self, prompt: str) -> Tuple[str, str]:\n",
    "        normalized = prompt.lower().strip()\n",
    "        if self.ml_handler:  # plug in semantic search or an LLM later\n",
    "            ml_answer = self.ml_handler(prompt)\n",
    "            if ml_answer:\n",
    "                return ml_answer, \"ml_handler\"\n",
    "\n",
    "        best_answer = None\n",
    "        best_question = None\n",
    "        best_score = 0\n",
    "        for item in self.faqs:\n",
    "            score = self._score(normalized, item[\"keywords\"])\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_answer = item[\"answer\"]\n",
    "                best_question = item[\"question\"]\n",
    "\n",
    "        if best_answer is None:\n",
    "            fallback = (\n",
    "                \"I do not have that in my notes yet. Could you try rephrasing or \"\n",
    "                \"contact our team at support@woodpecker.com?\"\n",
    "            )\n",
    "            return fallback, \"fallback\"\n",
    "\n",
    "        return best_answer, best_question or \"faq\"\n",
    "\n",
    "\n",
    "brain = SimpleRetailBrain(faq_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "837473e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# --- 2. Helper Functions ---\n",
    "\n",
    "def format_answer(answer: str, source: str) -> str:\n",
    "    \"\"\"Adds a timestamp and source label to the bot's reply.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    return f\"[{timestamp}] ({source}) {answer}\"\n",
    "\n",
    "\n",
    "def summarize_entities(ner_results) -> Dict[str, List[str]]:\n",
    "    \"\"\"Group detected entities by their BERT labels (PER, ORG, LOC, etc.).\"\"\"\n",
    "    if not ner_results:\n",
    "        return {}\n",
    "        \n",
    "    summary: Dict[str, List[str]] = defaultdict(list)\n",
    "    for ent in ner_results:\n",
    "        # Transformers pipeline with aggregation_strategy='simple' returns 'entity_group'\n",
    "        label = ent['entity_group']\n",
    "        text = ent['word']\n",
    "        summary[label].append(text)\n",
    "    \n",
    "    # Deduplicate while preserving order for readability\n",
    "    return {label: sorted(set(values), key=values.index) for label, values in summary.items()}\n",
    "\n",
    "\n",
    "def analyze_text_simple(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Runs a pure Transformers (BERT) pipeline.\n",
    "    Steps: BERT Tokenizer -> BERT POS -> BERT NER -> BERT Sentiment\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"Please enter text to analyze.\"\n",
    "\n",
    "    # 1. Tokenization (BERT Tokenizer)\n",
    "    # We use the tokenizer directly to show the sub-word tokens\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # 2. POS Tagging (BERT Model)\n",
    "    if pos_pipeline:\n",
    "        pos_data = pos_pipeline(text)\n",
    "        # Format: \"word (TAG)\" - BERT POS models often return tags like 'NOUN', 'VERB'\n",
    "        readable_pos = [f\"{item['word']} ({item['entity']})\" for item in pos_data]\n",
    "    else:\n",
    "        readable_pos = [\"(POS Model not loaded)\"]\n",
    "\n",
    "    # 3. NER (BERT Model)\n",
    "    if ner_pipeline:\n",
    "        ner_data = ner_pipeline(text)\n",
    "        entities_by_label = summarize_entities(ner_data)\n",
    "    else:\n",
    "        entities_by_label = \"(NER Model not loaded)\"\n",
    "\n",
    "    # 4. Sentiment (DistilBERT)\n",
    "    sentiment = sentiment_analyzer(text)[0]\n",
    "\n",
    "    return (\n",
    "        f\"### Analysis of: '{text}'\\n\\n\"\n",
    "        f\"**1. BERT Tokens:** {tokens}\\n\\n\"\n",
    "        f\"**2. POS Tags:** {', '.join(readable_pos)}\\n\\n\"\n",
    "        f\"**3. Entities (BERT NER):** {entities_by_label or 'None'}\\n\\n\"\n",
    "        f\"**4. Sentiment:** {sentiment['label']} ({sentiment['score']:.2f})\"\n",
    "    )\n",
    "\n",
    "# --- 3. Chatbot Logic ---\n",
    "\n",
    "def respond(message: str, history: List[Dict[str, str]], mode: str):\n",
    "    \"\"\"Main function called by Gradio when user sends a message.\"\"\"\n",
    "    history = history or [{\"role\": \"assistant\", \"content\": GREETING_MESSAGE}]\n",
    "\n",
    "    if mode == \"Sentiment pipeline\":\n",
    "        result = sentiment_analyzer(message)[0]\n",
    "        reply = f\"Sentiment: {result['label']} (Score: {result['score']:.2f})\"\n",
    "        source = \"sentiment-model\"\n",
    "    else:\n",
    "        reply, source = brain.answer(message)\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": format_answer(reply, source)})\n",
    "    return history, \"\"\n",
    "\n",
    "\n",
    "def reset_chat():\n",
    "    return [{\"role\": \"assistant\", \"content\": GREETING_MESSAGE}], \"\"\n",
    "\n",
    "# --- 4. UI Configuration ---\n",
    "CUSTOM_CSS = \"\"\"\n",
    "#chatbot .message.user { background-color: #fff4cf; color: #663c00; }\n",
    "#chatbot .message.bot { background-color: #dceeff; color: #003355; }\n",
    "\"\"\"\n",
    "STYLE_TAG = f\"<style>{CUSTOM_CSS}</style>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68102352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 7860): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted\n",
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 7861): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted\n",
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 7861): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted\n",
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 7862): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted\n",
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 7862): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(STYLE_TAG)\n",
    "    gr.Markdown(\"\"\"\n",
    "**How to use this sandbox**\n",
    "1. **Chat**: Ask Wood Pecker about orders, returns, promos, shipping, hours, etc.\n",
    "2. **Modes**: Choose **Manual data (FAQs)** for rule-based answers or **Sentiment pipeline** for the transformers option.\n",
    "3. **NLP Practice**: Use the **User feedback** box on the right to test the integrated NLP pipeline (Tokenization -> POS -> NER -> Sentiment). Try a sentence like: *\"Serena Williams won Wimbledon in 2016.\"*\n",
    "\"\"\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"### Chat with Wood Pecker\")\n",
    "            chatbot = gr.Chatbot(\n",
    "                label=\"Wood Pecker\",\n",
    "                height=420,\n",
    "                elem_id=\"chatbot\",\n",
    "                value=[{\"role\": \"assistant\", \"content\": GREETING_MESSAGE}],\n",
    "            )\n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    label=\"Ask a question\",\n",
    "                    placeholder=\"e.g., How fast is shipping?\",\n",
    "                    elem_classes=[\"input-box\"],\n",
    "                    scale=3,\n",
    "                )\n",
    "                mode = gr.Radio(\n",
    "                    choices=[MODE_MANUAL, MODE_SENTIMENT],\n",
    "                    value=MODE_MANUAL,\n",
    "                    label=\"Answer mode\",\n",
    "                    info=\"Option 1 = manual data, Option 2 = transformers sentiment pipeline.\",\n",
    "                    scale=1,\n",
    "                )\n",
    "            msg.submit(respond, inputs=[msg, chatbot, mode], outputs=[chatbot, msg])\n",
    "            clear = gr.Button(\"Clear conversation\")\n",
    "            clear.click(reset_chat, None, [chatbot, msg], queue=False)\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### User feedback / NLP Lab\")\n",
    "            feedback_input = gr.Textbox(\n",
    "                label=\"Share your experience (or test text)\",\n",
    "                placeholder=\"Type any text here to analyze...\",\n",
    "                lines=4,\n",
    "                elem_classes=[\"input-box\"],\n",
    "            )\n",
    "            feedback_button = gr.Button(\"Analyze NLP Pipeline\")\n",
    "            feedback_result = gr.Markdown(value=\"Awaiting input...\")\n",
    "            feedback_button.click(analyze_feedback, inputs=feedback_input, outputs=feedback_result)\n",
    "    gr.Markdown(\"\"\"\n",
    "_Tip_: to test a future ML model, pass a callable to `brain.set_ml_handler` that takes the prompt and returns a custom string. Leave it `None` to stay purely rule-based.\n",
    "\"\"\")\n",
    "\n",
    "# Launch on any available port to avoid conflicts when rerunning in notebooks.\n",
    "demo.launch(server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6252f",
   "metadata": {},
   "source": [
    "## ðŸš€ Next Steps: Making it Smarter\n",
    "\n",
    "Once you understand the basics, here is how you could upgrade this bot:\n",
    "\n",
    "*   **Semantic Search**: Instead of matching keywords (\"shipping\"), use vectors to match meaning (\"how do I get my stuff?\").\n",
    "*   **API Integration**: Connect the \"Order Status\" answer to a real database to give live updates.\n",
    "*   **Context Awareness**: Make the bot remember your name or previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0330f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety net: close any previously running Gradio demo before relaunching.\n",
    "try:\n",
    "    demo.close()\n",
    "except NameError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
